{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515f050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package\n",
    "import numpy as np; from scipy import stats; import matplotlib.pyplot as plt; import pymc as pm;import arviz as az; \n",
    "import math; import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import root\n",
    "from scipy import special\n",
    "import pytensor.tensor as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import fsolve\n",
    "from sympy import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2649b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Corr_identity(p):\n",
    "\n",
    "    Sigma = np.zeros((p-1, p-1))\n",
    "    np.fill_diagonal(Sigma, 1)\n",
    "    return Sigma\n",
    "\n",
    "def generate_data(n, p, sigma_sqr, beta, nu, corr):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    x_i = np.random.normal(0, 1, (n, p - 1))\n",
    "    x_i_correlated = x_i @ corr\n",
    "    ones = np.ones((n, 1))\n",
    "    x_i_full =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "    XB = x_i_full @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y, x_i_full,x_i\n",
    "    \n",
    "# full likelihood\n",
    "def negative_log_likelihood(params):\n",
    "    betas, sigma, nu = params[:-2], params[-2], params[-1]\n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(betas, (p, 1))\n",
    "    XB = X @ B\n",
    "    n = X.shape[0]\n",
    "    XB = XB.reshape((n, 1))\n",
    "    \n",
    "    # loglikelihood\n",
    "    equation = n * np.log(special.gamma((nu + 1)/2)) + n* nu *0.5 * np.log(nu) - n * np.log(special.gamma(nu/2)) - 0.5*n*np.log(np.pi) - n * np.log(sigma) - 0.5 *(nu + 1)*np.sum(np.log(nu + ((y - XB)/sigma)**2))\n",
    "    return -equation\n",
    "\n",
    "# Jeffrey's prior\n",
    "def logJeff(x):\n",
    "    return np.log((x/(x+3))**(1/2)*(special.polygamma(1,x/2) - special.polygamma(1, (x+1)/2) - 2*(x+3)/(x*(x+1)**2))**(1/2))\n",
    "\n",
    "# full joint with Jeff and 1/sigma priors\n",
    "def negative_full_joint(params):\n",
    "    nu = params[-1]\n",
    "    sigma = params[-2]\n",
    "    return -logJeff(nu) - np.log(1/sigma) + negative_log_likelihood(params)\n",
    "\n",
    "def initial_guess_from_lin_reg(x_without_1, y,nu_origin):\n",
    "    initial_guess = []\n",
    "    \n",
    "    model = LinearRegression().fit(x_without_1, y)\n",
    "    # intercept \n",
    "    initial_guess.append(float(model.intercept_))\n",
    "    # coeff\n",
    "    for coeff in model.coef_[0]:\n",
    "        initial_guess.append(coeff)\n",
    "    # sigma_sq    \n",
    "    y_pred = model.predict(x_without_1)\n",
    "    residual_sq = (((y - y_pred)**2).sum())/(n-2)\n",
    "    initial_guess.append(residual_sq)\n",
    "    \n",
    "    # nu\n",
    "    initial_guess.append(nu_origin) # use true nu for initial guess\n",
    "    return initial_guess\n",
    "\n",
    "def optimizer_all_three_params_least_sq(eqt, initial_guess,method_name):\n",
    "    p = X.shape[1]\n",
    "    bounds = [(None, None)] * p +[(0, np.inf)]*2\n",
    "    result = minimize(eqt, initial_guess, method= method_name,bounds = bounds, options={'maxiter':1000})\n",
    "    return result\n",
    "\n",
    "def fix_x_generate_data(n, p, sigma_sqr, beta, nu, corr,X):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    XB = X @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y\n",
    "\n",
    "def hessian_sigma_prior(sigma):\n",
    "    return 1/sigma**2\n",
    "\n",
    "def hessian_likelihood(beta,sigma, nu): \n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(beta, (p, 1))\n",
    "    XB = X @ B\n",
    "    XB = XB.reshape((n, 1))\n",
    "    Z = XB/sigma_sqr\n",
    "\n",
    "    # Adopted from W6 \n",
    "    total_b2 = 0\n",
    "    total_b_sigma = 0\n",
    "    total_sigma_b = 0\n",
    "    total_s2 = 0\n",
    "    for i in range(n):\n",
    "            Xi = np.reshape(X[i,:], (p, 1))\n",
    "            residual = y[i] - X[i, :] @ beta\n",
    "            nu_sigma_sqr_plus_residual =  nu*(sigma**2)+ residual**2\n",
    "            total_b2 = total_b2 + (- (nu_sigma_sqr_plus_residual)* np.outer(X[i,:],X[i, :]) + np.outer(X[i, :], X[i, :])*2*(residual**2))/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_sigma_b = total_sigma_b + (-2*nu*sigma*X[i,:]*residual)/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_s2 = total_s2 - 3 * (residual ** 2) / nu_sigma_sqr_plus_residual + ((residual ** 4) * 2 ) / (nu_sigma_sqr_plus_residual ** 2) \n",
    "\n",
    "    db2 = -1 * total_b2 * (nu+1)\n",
    "    dsb = -1 * total_sigma_b * (nu+1)\n",
    "    dbs = dsb\n",
    "    ds2 = -1 * (n / (sigma ** 2) + (nu + 1) * total_s2/(sigma**2))\n",
    "\n",
    "    dv2 = n/4 * (special.polygamma(1, (nu+1)/2) - special.polygamma(1, nu/2)) + 1/2 * np.sum((Z**2)/(nu + (Z**2)) - (Z**2 -1)/(nu + (Z**2))**2)\n",
    "\n",
    "    nu_sym = symbols('nu_sym')\n",
    "    sigma_eqt = -n/2 + (nu_sym+1)/2 * np.sum(1/(nu_sym + (Z**2)) *2*Z * (y-XB)/(sigma**2))\n",
    "    sigma_eqt= Derivative(sigma_eqt, nu_sym) \n",
    "    sigma_eqt_diff = sigma_eqt.doit()\n",
    "    dsv = sigma_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "    dvs = dsv\n",
    "\n",
    "    beta0_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,0])\n",
    "    beta0_eqt= Derivative(beta0_eqt, nu_sym) \n",
    "    beta0_eqt_diff = beta0_eqt.doit()\n",
    "    db0v = beta0_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta1_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,1])\n",
    "    beta1_eqt= Derivative(beta1_eqt, nu_sym) \n",
    "    beta1_eqt_diff = beta1_eqt.doit()\n",
    "    db1v = beta1_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta2_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,2])\n",
    "    beta2_eqt= Derivative(beta2_eqt, nu_sym) \n",
    "    beta2_eqt_diff = beta2_eqt.doit()\n",
    "    db2v = beta2_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta3_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,3])\n",
    "    beta3_eqt= Derivative(beta3_eqt, nu_sym) \n",
    "    beta3_eqt_diff = beta3_eqt.doit()\n",
    "    db3v = beta3_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta4_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,4])\n",
    "    beta4_eqt= Derivative(beta4_eqt, nu_sym) \n",
    "    beta4_eqt_diff = beta4_eqt.doit()\n",
    "    db4v = beta4_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    dbv = np.array([db0v,db1v,db2v,db3v,db4v])\n",
    "    dvb = dbv\n",
    "\n",
    "    hessian_likelihood = np.zeros((p + 2, p + 2))\n",
    "    hessian_likelihood[:p, :p] = db2\n",
    "    hessian_likelihood[:p, p] = dbs\n",
    "    hessian_likelihood[p, :p] = dsb\n",
    "    hessian_likelihood[p, p] = ds2\n",
    "    hessian_likelihood[-1,-1] = dv2\n",
    "    hessian_likelihood[-2,-1] = dsv\n",
    "    hessian_likelihood[-1,-2] = dvs\n",
    "    hessian_likelihood[:p,p+1] = dbv\n",
    "    hessian_likelihood[p+1,:p] = dvb\n",
    "    \n",
    "    return hessian_likelihood\n",
    "\n",
    "def hessian_likelihood(beta,sigma, nu): \n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(beta, (p, 1))\n",
    "    XB = X @ B\n",
    "    XB = XB.reshape((n, 1))\n",
    "    Z = XB/sigma_sqr\n",
    "\n",
    "    # Adopted from W6 \n",
    "    total_b2 = 0\n",
    "    total_b_sigma = 0\n",
    "    total_sigma_b = 0\n",
    "    total_s2 = 0\n",
    "    for i in range(n):\n",
    "            Xi = np.reshape(X[i,:], (p, 1))\n",
    "            residual = y[i] - X[i, :] @ beta\n",
    "            nu_sigma_sqr_plus_residual =  nu*(sigma**2)+ residual**2\n",
    "            total_b2 = total_b2 + (- (nu_sigma_sqr_plus_residual)* np.outer(X[i,:],X[i, :]) + np.outer(X[i, :], X[i, :])*2*(residual**2))/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_sigma_b = total_sigma_b + (-2*nu*sigma*X[i,:]*residual)/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_s2 = total_s2 - 3 * (residual ** 2) / nu_sigma_sqr_plus_residual + ((residual ** 4) * 2 ) / (nu_sigma_sqr_plus_residual ** 2) \n",
    "\n",
    "    db2 = -1 * total_b2 * (nu+1)\n",
    "    dsb = -1 * total_sigma_b * (nu+1)\n",
    "    dbs = dsb\n",
    "    ds2 = -1 * (n / (sigma ** 2) + (nu + 1) * total_s2/(sigma**2))\n",
    "\n",
    "    dv2 = n/4 * (special.polygamma(1, (nu+1)/2) - special.polygamma(1, nu/2)) + 1/2 * np.sum((Z**2)/(nu + (Z**2)) - (Z**2 -1)/(nu + (Z**2))**2)\n",
    "\n",
    "    nu_sym = symbols('nu_sym')\n",
    "    sigma_eqt = -n/2 + (nu_sym+1)/2 * np.sum(1/(nu_sym + (Z**2)) *2*Z * (y-XB)/(sigma**2))\n",
    "    sigma_eqt= Derivative(sigma_eqt, nu_sym) \n",
    "    sigma_eqt_diff = sigma_eqt.doit()\n",
    "    dsv = sigma_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "    dvs = dsv\n",
    "\n",
    "    beta0_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,0])\n",
    "    beta0_eqt= Derivative(beta0_eqt, nu_sym) \n",
    "    beta0_eqt_diff = beta0_eqt.doit()\n",
    "    db0v = beta0_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta1_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,1])\n",
    "    beta1_eqt= Derivative(beta1_eqt, nu_sym) \n",
    "    beta1_eqt_diff = beta1_eqt.doit()\n",
    "    db1v = beta1_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta2_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,2])\n",
    "    beta2_eqt= Derivative(beta2_eqt, nu_sym) \n",
    "    beta2_eqt_diff = beta2_eqt.doit()\n",
    "    db2v = beta2_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta3_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,3])\n",
    "    beta3_eqt= Derivative(beta3_eqt, nu_sym) \n",
    "    beta3_eqt_diff = beta3_eqt.doit()\n",
    "    db3v = beta3_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta4_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,4])\n",
    "    beta4_eqt= Derivative(beta4_eqt, nu_sym) \n",
    "    beta4_eqt_diff = beta4_eqt.doit()\n",
    "    db4v = beta4_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    dbv = np.array([db0v,db1v,db2v,db3v,db4v])\n",
    "    dvb = dbv\n",
    "\n",
    "    hessian_likelihood = np.zeros((p + 2, p + 2))\n",
    "    hessian_likelihood[:p, :p] = db2\n",
    "    hessian_likelihood[:p, p] = dbs\n",
    "    hessian_likelihood[p, :p] = dsb\n",
    "    hessian_likelihood[p, p] = ds2\n",
    "    hessian_likelihood[-1,-1] = dv2\n",
    "    hessian_likelihood[-2,-1] = dsv\n",
    "    hessian_likelihood[-1,-2] = dvs\n",
    "    hessian_likelihood[:p,p+1] = dbv\n",
    "    hessian_likelihood[p+1,:p] = dvb\n",
    "    \n",
    "    return hessian_likelihood\n",
    "\n",
    "def hessian_nu_Jeff_prior(x):\n",
    "    term1 = (x + 3)*(1.0*x/(x + 3)**3 - 1.0/(x + 3)**2)/x + (-0.5*x/(x + 3)**2 + 0.5/(x + 3))/x - (x + 3)*(-0.5*x/(x + 3)**2 + 0.5/(x + 3))/x**2\n",
    "    term2 = 1/(2*(special.polygamma(1,x/2) - special.polygamma(1, (x+1)/2) - 2*(x+3)/(x*(x+1)**2)))\n",
    "    term3 = 1/4*special.polygamma(3,x/2)\n",
    "    term4 = 1/4*special.polygamma(3,(x+1)/2)\n",
    "    term5 = -8/(x*(x + 1)**3) + 3*(4*x + 12)/(x*(x + 1)**4) - 4/(x**2*(x + 1)**2) + 2*(2*x + 6)/(x**2*(x + 1)**3) + (4*x + 12)/(x**2*(x + 1)**3) + 2*(2*x + 6)/(x**3*(x + 1)**2)\n",
    "    return term1 + term2* (term3 - term4 - term5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8edc9d",
   "metadata": {},
   "source": [
    "# Task 1: CI for betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e58088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error_beta(beta,sigma,nu):\n",
    "    Hessian_L = hessian_likelihood(beta,sigma,nu)\n",
    "    hessian_S = hessian_sigma_prior(sigma)\n",
    "    hessian_nu = hessian_nu_Jeff_prior(nu)\n",
    "    Hessian_L[p][p] += hessian_S\n",
    "    Hessian_L[-1][-1] += hessian_nu\n",
    "    hessian_inverse = np.linalg.inv(Hessian_L)\n",
    "    \n",
    "    sd_beta_0 = np.sqrt(abs(hessian_inverse[0][0]))\n",
    "    sd_beta_1 = np.sqrt(abs(hessian_inverse[1][1]))\n",
    "    sd_beta_2 = np.sqrt(abs(hessian_inverse[2][2]))\n",
    "    sd_beta_3 = np.sqrt(abs(hessian_inverse[3][3]))\n",
    "    sd_beta_4 = np.sqrt(abs(hessian_inverse[4][4]))\n",
    "    \n",
    "    return sd_beta_0,sd_beta_1,sd_beta_2,sd_beta_3,sd_beta_4\n",
    "\n",
    "def confidence_interval_beta(beta_MAP, beta_sd):\n",
    "    upper_interval = beta_MAP + 1.96*beta_sd\n",
    "    lower_interval = beta_MAP - 1.96*beta_sd\n",
    "    return [lower_interval,upper_interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2901e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_mse_function(true_beta_list, MAP_list):\n",
    "    n = len(MAP_list)\n",
    "    if n == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        MAP_list = np.array(MAP_list)\n",
    "        MAP_list = MAP_list.transpose()\n",
    "        \n",
    "        beta_mse = []\n",
    "        for j in range(len(true_beta_list)):\n",
    "            b_list = MAP_list[j]\n",
    "            true_beta = true_beta_list[j]\n",
    "            beta_origin_vec = true_beta * np.ones((n, 1))\n",
    "            mse = np.sum((b_list - beta_origin_vec)**2) / n\n",
    "            result = np.sqrt(mse)/true_beta\n",
    "            beta_mse.append(result)\n",
    "        \n",
    "        return beta_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f01d6",
   "metadata": {},
   "source": [
    "## Nelder- Mead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4832af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Fix number of observations\n",
    "n = 50\n",
    "p = 5\n",
    "beta = np.array([2, 1, 0.3, 0.9, 1])\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "for nu_origin in range(5,26,5):\n",
    "\n",
    "    beta_MAP_list = []\n",
    "    beta_0_count_include_in_CI = 0\n",
    "    beta_1_count_include_in_CI = 0\n",
    "    beta_2_count_include_in_CI = 0\n",
    "    beta_3_count_include_in_CI = 0\n",
    "    beta_4_count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(50): # number of simulations \n",
    "        y = fix_x_generate_data(n, p, sigma_sqr, beta, nu_origin, corr, X) \n",
    "        \n",
    "        # Maximize log joint with Nedler- Mead algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y,nu_origin)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_full_joint, initial_guess, 'Nelder-Mead')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            \n",
    "            # MAP\n",
    "            nu_MAP = profile_lse_joint_result.x[-1]\n",
    "            beta_MAP = profile_lse_joint_result.x[:p]\n",
    "            sigma_MAP = profile_lse_joint_result.x[-2]\n",
    "            beta_MAP_list.append(beta_MAP)\n",
    "\n",
    "            # SD\n",
    "            sd_beta_0,sd_beta_1,sd_beta_2,sd_beta_3,sd_beta_4 = standard_error_beta(beta_MAP,sigma_MAP,nu_MAP)\n",
    "            \n",
    "            # CI\n",
    "            beta_0_CI = confidence_interval_beta(beta_MAP[0], sd_beta_0)\n",
    "            beta_1_CI = confidence_interval_beta(beta_MAP[1], sd_beta_1)\n",
    "            beta_2_CI = confidence_interval_beta(beta_MAP[2], sd_beta_2)\n",
    "            beta_3_CI = confidence_interval_beta(beta_MAP[3], sd_beta_3)\n",
    "            beta_4_CI = confidence_interval_beta(beta_MAP[4], sd_beta_4)\n",
    "            \n",
    "            # CI capture true betas?\n",
    "            beta_0_count_include_in_CI += beta_0_CI[0]<= beta[0]<= beta_0_CI[1]\n",
    "            beta_1_count_include_in_CI += beta_1_CI[0]<= beta[1]<= beta_1_CI[1]\n",
    "            beta_2_count_include_in_CI += beta_2_CI[0]<= beta[2]<= beta_2_CI[1]\n",
    "            beta_3_count_include_in_CI += beta_3_CI[0]<= beta[3]<= beta_3_CI[1]\n",
    "            beta_4_count_include_in_CI += beta_4_CI[0]<= beta[4]<= beta_4_CI[1]\n",
    "    \n",
    "    beta_count_include_in_CI = [beta_0_count_include_in_CI,beta_1_count_include_in_CI,beta_2_count_include_in_CI,beta_3_count_include_in_CI,beta_4_count_include_in_CI]\n",
    "    \n",
    "    beta_mse = beta_mse_function(beta, beta_MAP_list)\n",
    "    final_dict[nu_origin] = [beta_count_include_in_CI,len(beta_MAP_list), beta_mse]\n",
    "    print(nu_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b799488e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [[17, 44, 46, 40, 47],\n",
       "  50,\n",
       "  [0.7450647789422626,\n",
       "   1.4368274294530023,\n",
       "   4.057479761507989,\n",
       "   1.6608099465905877,\n",
       "   1.2737170322006035]],\n",
       " 10: [[20, 45, 43, 47, 47],\n",
       "  50,\n",
       "  [0.8047183216168271,\n",
       "   1.2896047215138904,\n",
       "   5.075380204012951,\n",
       "   1.4470235830130211,\n",
       "   1.4654969704698055]],\n",
       " 15: [[15, 41, 45, 46, 44],\n",
       "  50,\n",
       "  [0.7372810066585116,\n",
       "   1.4085395300146322,\n",
       "   4.347956155201788,\n",
       "   1.4747428540286949,\n",
       "   1.5935592226954602]],\n",
       " 20: [[17, 46, 44, 42, 40],\n",
       "  50,\n",
       "  [0.8476683634921037,\n",
       "   1.1819327679179599,\n",
       "   3.916949518334949,\n",
       "   1.6862288992211236,\n",
       "   1.5541258271332417]],\n",
       " 25: [[17, 46, 45, 44, 45],\n",
       "  49,\n",
       "  [0.6998002360621626,\n",
       "   1.1631076248759216,\n",
       "   3.2649124883886924,\n",
       "   1.5917572356613627,\n",
       "   1.4248895755038091]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139db958",
   "metadata": {},
   "source": [
    "# Task 2: Fit data with Normal error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d4b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_x_generate_norm_data(n, p, sigma_sqr, beta, corr,X):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    XB = X @ beta\n",
    "    E = stats.norm.rvs(loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ee989de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.31780219]\n",
      " [-0.03030688]\n",
      " [ 0.26285322]\n",
      " [-1.24057971]\n",
      " [ 0.43951594]]\n",
      "[[ 0.22969871]\n",
      " [-2.09178028]\n",
      " [ 0.15318667]\n",
      " [-0.47292646]\n",
      " [ 0.2248167 ]]\n",
      "[[ 1.4594033 ]\n",
      " [ 0.55418151]\n",
      " [ 0.09261323]\n",
      " [ 0.01396648]\n",
      " [-0.8364693 ]]\n",
      "[[-0.65508941]\n",
      " [ 0.48026789]\n",
      " [-0.55859682]\n",
      " [-0.24071861]\n",
      " [-0.24604499]]\n",
      "[[-0.42075152]\n",
      " [-0.43579238]\n",
      " [ 0.18818697]\n",
      " [ 0.47646982]\n",
      " [-0.06789239]]\n",
      "[[ 0.42081536]\n",
      " [-0.17084315]\n",
      " [ 0.4954618 ]\n",
      " [ 2.48472171]\n",
      " [ 0.74023399]]\n",
      "[[ 0.45167746]\n",
      " [ 0.23233416]\n",
      " [-0.61989875]\n",
      " [ 0.88229321]\n",
      " [-0.54007581]]\n",
      "[[-2.27037435]\n",
      " [-0.20465844]\n",
      " [ 0.6543312 ]\n",
      " [-0.78134476]\n",
      " [-1.12798419]]\n",
      "[[-0.06054198]\n",
      " [ 1.41928692]\n",
      " [ 0.03931046]\n",
      " [-1.53916308]\n",
      " [-0.81462937]]\n",
      "[[-1.47694556]\n",
      " [ 0.8065151 ]\n",
      " [ 0.62117603]\n",
      " [-1.19191685]\n",
      " [-0.44545092]]\n"
     ]
    }
   ],
   "source": [
    "# Fix number of observations\n",
    "n = 50\n",
    "p = 5\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    beta = stats.norm.rvs(loc=0, scale= 1, size=(5, 1))\n",
    "    \n",
    "    beta_MAP_list = []\n",
    "    beta_0_count_include_in_CI = 0\n",
    "    beta_1_count_include_in_CI = 0\n",
    "    beta_2_count_include_in_CI = 0\n",
    "    beta_3_count_include_in_CI = 0\n",
    "    beta_4_count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(50): # number of simulations \n",
    "        y = fix_x_generate_norm_data(n, p, sigma_sqr, beta, corr, X) \n",
    "        \n",
    "        # Maximize log joint with Nedler- Mead algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y, 10)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_full_joint, initial_guess, 'Nelder-Mead')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            \n",
    "            # MAP\n",
    "            nu_MAP = profile_lse_joint_result.x[-1]\n",
    "            beta_MAP = profile_lse_joint_result.x[:p]\n",
    "            sigma_MAP = profile_lse_joint_result.x[-2]\n",
    "            beta_MAP_list.append(beta_MAP)\n",
    "\n",
    "            # SD\n",
    "            sd_beta_0,sd_beta_1,sd_beta_2,sd_beta_3,sd_beta_4 = standard_error_beta(beta_MAP,sigma_MAP,nu_MAP)\n",
    "            \n",
    "            # CI\n",
    "            beta_0_CI = confidence_interval_beta(beta_MAP[0], sd_beta_0)\n",
    "            beta_1_CI = confidence_interval_beta(beta_MAP[1], sd_beta_1)\n",
    "            beta_2_CI = confidence_interval_beta(beta_MAP[2], sd_beta_2)\n",
    "            beta_3_CI = confidence_interval_beta(beta_MAP[3], sd_beta_3)\n",
    "            beta_4_CI = confidence_interval_beta(beta_MAP[4], sd_beta_4)\n",
    "            \n",
    "            # CI capture true betas?\n",
    "            beta_0_count_include_in_CI += beta_0_CI[0]<= beta[0]<= beta_0_CI[1]\n",
    "            beta_1_count_include_in_CI += beta_1_CI[0]<= beta[1]<= beta_1_CI[1]\n",
    "            beta_2_count_include_in_CI += beta_2_CI[0]<= beta[2]<= beta_2_CI[1]\n",
    "            beta_3_count_include_in_CI += beta_3_CI[0]<= beta[3]<= beta_3_CI[1]\n",
    "            beta_4_count_include_in_CI += beta_4_CI[0]<= beta[4]<= beta_4_CI[1]\n",
    "    \n",
    "    beta_count_include_in_CI = [beta_0_count_include_in_CI,beta_1_count_include_in_CI,beta_2_count_include_in_CI,beta_3_count_include_in_CI,beta_4_count_include_in_CI]\n",
    "    \n",
    "    beta_mse = beta_mse_function(beta, beta_MAP_list)\n",
    "    final_dict[i] = [beta_count_include_in_CI,len(beta_MAP_list), beta_mse]\n",
    "    print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0a54551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[array([13]), array([46]), array([49]), array([44]), array([48])],\n",
       "  50,\n",
       "  [array([1.0903287]),\n",
       "   array([-36.76342088]),\n",
       "   array([3.92673254]),\n",
       "   array([-1.2137255]),\n",
       "   array([2.61601536])]],\n",
       " 1: [[array([22]), array([43]), array([46]), array([46]), array([46])],\n",
       "  50,\n",
       "  [array([6.326159]),\n",
       "   array([-0.56929571]),\n",
       "   array([6.96718093]),\n",
       "   array([-2.75508294]),\n",
       "   array([5.1392537])]],\n",
       " 2: [[array([8]), array([41]), array([44]), array([44]), array([49])],\n",
       "  50,\n",
       "  [array([0.84436856]),\n",
       "   array([2.53440385]),\n",
       "   array([14.42452337]),\n",
       "   array([112.73988511]),\n",
       "   array([-1.17783408])]],\n",
       " 3: [[array([40]), array([44]), array([41]), array([46]), array([43])],\n",
       "  50,\n",
       "  [array([-2.18142154]),\n",
       "   array([2.64596177]),\n",
       "   array([-2.2248102]),\n",
       "   array([-5.69675713]),\n",
       "   array([-5.31298878])]],\n",
       " 4: [[array([36]), array([47]), array([45]), array([47]), array([46])],\n",
       "  49,\n",
       "  [array([-3.1470206]),\n",
       "   array([-2.07198573]),\n",
       "   array([5.54303894]),\n",
       "   array([2.61104135]),\n",
       "   array([-17.26762337])]],\n",
       " 5: [[array([37]), array([44]), array([47]), array([48]), array([41])],\n",
       "  50,\n",
       "  [array([3.56831028]),\n",
       "   array([-9.55746443]),\n",
       "   array([2.3543158]),\n",
       "   array([0.5210073]),\n",
       "   array([1.92883758])]],\n",
       " 6: [[array([39]), array([47]), array([44]), array([44]), array([42])],\n",
       "  50,\n",
       "  [array([2.68558333]),\n",
       "   array([4.66086364]),\n",
       "   array([-1.87767787]),\n",
       "   array([1.47871853]),\n",
       "   array([-2.36145685])]],\n",
       " 7: [[array([13]), array([45]), array([46]), array([49]), array([47])],\n",
       "  50,\n",
       "  [array([-0.60328406]),\n",
       "   array([-6.23124471]),\n",
       "   array([1.59646911]),\n",
       "   array([-1.34955758]),\n",
       "   array([-0.96221336])]],\n",
       " 8: [[array([44]), array([43]), array([44]), array([39]), array([45])],\n",
       "  50,\n",
       "  [array([-18.04496534]),\n",
       "   array([0.90729455]),\n",
       "   array([31.26556521]),\n",
       "   array([-1.0818499]),\n",
       "   array([-1.4784606])]],\n",
       " 9: [[array([10]), array([45]), array([41]), array([45]), array([42])],\n",
       "  50,\n",
       "  [array([-0.87975223]),\n",
       "   array([1.4371149]),\n",
       "   array([2.16376454]),\n",
       "   array([-1.05271205]),\n",
       "   array([-3.30861376])]]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa3ce7",
   "metadata": {},
   "source": [
    "# Task 3: Fit data with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e25deddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_x_generate_norm_data(n, p, sigma_sqr, beta, corr,X):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    XB = X @ beta\n",
    "    E = stats.norm.rvs(loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7b21ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57248014]\n",
      " [ 1.86101118]\n",
      " [-1.05117132]\n",
      " [-0.44503235]\n",
      " [-0.80354711]]\n",
      "[[-0.58202719]\n",
      " [-0.05520919]\n",
      " [ 1.14312754]\n",
      " [-0.30112363]\n",
      " [-1.02744028]]\n",
      "[[ 0.49307819]\n",
      " [ 1.05909044]\n",
      " [-1.50951674]\n",
      " [ 0.1598098 ]\n",
      " [-1.63158692]]\n",
      "[[-1.86463373]\n",
      " [-1.34802929]\n",
      " [ 0.11990641]\n",
      " [-0.64673708]\n",
      " [-0.72995007]]\n",
      "[[-0.28379284]\n",
      " [ 2.27820937]\n",
      " [ 0.01417134]\n",
      " [-0.23225807]\n",
      " [-0.45867776]]\n",
      "[[-2.72081618]\n",
      " [ 0.82657523]\n",
      " [ 0.15053318]\n",
      " [ 0.56693376]\n",
      " [ 1.063035  ]]\n",
      "[[-0.09641213]\n",
      " [ 0.20173054]\n",
      " [-0.42150076]\n",
      " [-2.00697095]\n",
      " [ 1.05171477]]\n",
      "[[ 0.60200351]\n",
      " [-0.36921039]\n",
      " [ 0.3453198 ]\n",
      " [ 1.56647439]\n",
      " [ 0.0422946 ]]\n",
      "[[ 0.32041916]\n",
      " [ 0.58848548]\n",
      " [ 1.23940653]\n",
      " [-0.60239555]\n",
      " [-0.23367623]]\n",
      "[[-0.84095685]\n",
      " [ 0.35067329]\n",
      " [-0.7940624 ]\n",
      " [ 0.20686309]\n",
      " [-0.70907126]]\n"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "p = 5\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "for i in range(10):\n",
    "    beta = stats.norm.rvs(loc=0, scale= 1, size=(5, 1))\n",
    "    \n",
    "    beta_MAP_list = []\n",
    "    beta_0_count_include_in_CI = 0\n",
    "    beta_1_count_include_in_CI = 0\n",
    "    beta_2_count_include_in_CI = 0\n",
    "    beta_3_count_include_in_CI = 0\n",
    "    beta_4_count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(50): # number of simulations \n",
    "        non_outliers = fix_x_generate_norm_data(45, p, sigma_sqr, beta, corr, X[:45]) \n",
    "        outliers = np.array([[10],[15],[-13],[-19],[21]])\n",
    "        y = np.concatenate((non_outliers, outliers))\n",
    "        \n",
    "        # Maximize log joint with Nedler- Mead algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y, 10)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_full_joint, initial_guess, 'Nelder-Mead')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            \n",
    "            # MAP\n",
    "            nu_MAP = profile_lse_joint_result.x[-1]\n",
    "            beta_MAP = profile_lse_joint_result.x[:p]\n",
    "            sigma_MAP = profile_lse_joint_result.x[-2]\n",
    "            beta_MAP_list.append(beta_MAP)\n",
    "\n",
    "            # SD\n",
    "            sd_beta_0,sd_beta_1,sd_beta_2,sd_beta_3,sd_beta_4 = standard_error_beta(beta_MAP,sigma_MAP,nu_MAP)\n",
    "            \n",
    "            # CI\n",
    "            beta_0_CI = confidence_interval_beta(beta_MAP[0], sd_beta_0)\n",
    "            beta_1_CI = confidence_interval_beta(beta_MAP[1], sd_beta_1)\n",
    "            beta_2_CI = confidence_interval_beta(beta_MAP[2], sd_beta_2)\n",
    "            beta_3_CI = confidence_interval_beta(beta_MAP[3], sd_beta_3)\n",
    "            beta_4_CI = confidence_interval_beta(beta_MAP[4], sd_beta_4)\n",
    "            \n",
    "            # CI capture true betas?\n",
    "            beta_0_count_include_in_CI += beta_0_CI[0]<= beta[0]<= beta_0_CI[1]\n",
    "            beta_1_count_include_in_CI += beta_1_CI[0]<= beta[1]<= beta_1_CI[1]\n",
    "            beta_2_count_include_in_CI += beta_2_CI[0]<= beta[2]<= beta_2_CI[1]\n",
    "            beta_3_count_include_in_CI += beta_3_CI[0]<= beta[3]<= beta_3_CI[1]\n",
    "            beta_4_count_include_in_CI += beta_4_CI[0]<= beta[4]<= beta_4_CI[1]\n",
    "    \n",
    "    beta_count_include_in_CI = [beta_0_count_include_in_CI,beta_1_count_include_in_CI,beta_2_count_include_in_CI,beta_3_count_include_in_CI,beta_4_count_include_in_CI]\n",
    "    \n",
    "    beta_mse = beta_mse_function(beta, beta_MAP_list)\n",
    "    final_dict[i] = [beta_count_include_in_CI,len(beta_MAP_list), beta_mse]\n",
    "    print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "541fe2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[array([18]), array([34]), array([36]), array([28]), array([36])],\n",
       "  40,\n",
       "  [array([-4.63871247]),\n",
       "   array([2.22829539]),\n",
       "   array([-1.35037465]),\n",
       "   array([-5.89441485]),\n",
       "   array([-1.67851412])]],\n",
       " 1: [[array([25]), array([32]), array([32]), array([38]), array([34])],\n",
       "  42,\n",
       "  [array([-2.42958093]),\n",
       "   array([-29.95753132]),\n",
       "   array([1.17195315]),\n",
       "   array([-4.90409967]),\n",
       "   array([-1.29987666])]],\n",
       " 2: [[array([10]), array([11]), array([8]), array([14]), array([16])],\n",
       "  20,\n",
       "  [array([2.84122447]),\n",
       "   array([4.44743604]),\n",
       "   array([-3.12974051]),\n",
       "   array([13.40018412]),\n",
       "   array([-0.85960506])]],\n",
       " 3: [[array([11]), array([17]), array([20]), array([16]), array([21])],\n",
       "  24,\n",
       "  [array([-0.88460934]),\n",
       "   array([-1.17877132]),\n",
       "   array([9.93568414]),\n",
       "   array([-3.64027344]),\n",
       "   array([-1.73187989])]],\n",
       " 4: [[array([25]), array([31]), array([30]), array([34]), array([33])],\n",
       "  41,\n",
       "  [array([-6.35725909]),\n",
       "   array([0.826264]),\n",
       "   array([123.8433772]),\n",
       "   array([-7.91341481]),\n",
       "   array([-2.75421939])]],\n",
       " 5: [[array([14]), array([20]), array([21]), array([19]), array([21])],\n",
       "  28,\n",
       "  [array([-0.61178132]),\n",
       "   array([6.03643965]),\n",
       "   array([9.45459201]),\n",
       "   array([4.12045894]),\n",
       "   array([2.26566639])]],\n",
       " 6: [[array([13]), array([25]), array([21]), array([21]), array([23])],\n",
       "  30,\n",
       "  [array([-28.46432455]),\n",
       "   array([7.51625452]),\n",
       "   array([-4.44233677]),\n",
       "   array([-0.65767681]),\n",
       "   array([1.68719227])]],\n",
       " 7: [[array([14]), array([25]), array([27]), array([25]), array([27])],\n",
       "  32,\n",
       "  [array([2.80513825]),\n",
       "   array([-5.36669489]),\n",
       "   array([4.54713777]),\n",
       "   array([0.88236567]),\n",
       "   array([52.39266277])]],\n",
       " 8: [[array([9]), array([18]), array([17]), array([15]), array([18])],\n",
       "  21,\n",
       "  [array([4.69765042]),\n",
       "   array([3.37076019]),\n",
       "   array([0.86908721]),\n",
       "   array([-2.98802865]),\n",
       "   array([-4.84875099])]],\n",
       " 9: [[array([10]), array([18]), array([24]), array([21]), array([22])],\n",
       "  29,\n",
       "  [array([-3.12757202]),\n",
       "   array([9.0262083]),\n",
       "   array([-1.7245187]),\n",
       "   array([13.1653387]),\n",
       "   array([-2.40355076])]]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
