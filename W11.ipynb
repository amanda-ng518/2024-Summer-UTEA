{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af20b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package\n",
    "import numpy as np; from scipy import stats; import matplotlib.pyplot as plt; import pymc as pm;import arviz as az; \n",
    "import math; import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import root\n",
    "from scipy import special\n",
    "import pytensor.tensor as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import fsolve\n",
    "from sympy import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d535fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Corr_identity(p):\n",
    "\n",
    "    Sigma = np.zeros((p-1, p-1))\n",
    "    np.fill_diagonal(Sigma, 1)\n",
    "    return Sigma\n",
    "\n",
    "def generate_data(n, p, sigma_sqr, beta, nu, corr):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    x_i = np.random.normal(0, 1, (n, p - 1))\n",
    "    x_i_correlated = x_i @ corr\n",
    "    ones = np.ones((n, 1))\n",
    "    x_i_full =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "    XB = x_i_full @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y, x_i_full,x_i\n",
    "\n",
    "def calculate_y_axix(nu_origin, nu_est):\n",
    "    n = len(nu_est)\n",
    "    if n == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        nu_origin_vec = nu_origin * np.ones((n, 1))\n",
    "        mse = np.sum((nu_est - nu_origin_vec)**2) / n\n",
    "        result = np.sqrt(mse)/nu_origin\n",
    "        return result\n",
    "    \n",
    "# full likelihood\n",
    "def negative_log_likelihood(params):\n",
    "    betas, sigma, nu = params[:-2], params[-2], params[-1]\n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(betas, (p, 1))\n",
    "    XB = X @ B\n",
    "    n = X.shape[0]\n",
    "    XB = XB.reshape((n, 1))\n",
    "    \n",
    "    # loglikelihood\n",
    "    equation = n * np.log(special.gamma((nu + 1)/2)) + n* nu *0.5 * np.log(nu) - n * np.log(special.gamma(nu/2)) - 0.5*n*np.log(np.pi) - n * np.log(sigma) - 0.5 *(nu + 1)*np.sum(np.log(nu + ((y - XB)/sigma)**2))\n",
    "    return -equation\n",
    "\n",
    "# Jeffrey's prior\n",
    "def logJeff(x):\n",
    "    return np.log((x/(x+3))**(1/2)*(special.polygamma(1,x/2) - special.polygamma(1, (x+1)/2) - 2*(x+3)/(x*(x+1)**2))**(1/2))\n",
    "\n",
    "# full joint with Jeff and 1/sigma priors\n",
    "def negative_full_joint(params):\n",
    "    nu = params[-1]\n",
    "    sigma = params[-2]\n",
    "    return -logJeff(nu) - np.log(1/sigma) + negative_log_likelihood(params)\n",
    "\n",
    "def initial_guess_from_lin_reg(x_without_1, y,nu_origin):\n",
    "    initial_guess = []\n",
    "    \n",
    "    model = LinearRegression().fit(x_without_1, y)\n",
    "    # intercept \n",
    "    initial_guess.append(float(model.intercept_))\n",
    "    # coeff\n",
    "    for coeff in model.coef_[0]:\n",
    "        initial_guess.append(coeff)\n",
    "    # sigma_sq    \n",
    "    y_pred = model.predict(x_without_1)\n",
    "    residual_sq = (((y - y_pred)**2).sum())/(n-2)\n",
    "    initial_guess.append(residual_sq)\n",
    "    \n",
    "    # nu\n",
    "    initial_guess.append(nu_origin) # use true nu for initial guess\n",
    "    return initial_guess\n",
    "\n",
    "def optimizer_all_three_params_least_sq(eqt, initial_guess,method_name):\n",
    "    p = X.shape[1]\n",
    "    bounds = [(None, None)] * p +[(0, np.inf)]*2\n",
    "    result = minimize(eqt, initial_guess, method= method_name,bounds = bounds, options={'maxiter':1000})\n",
    "    return result\n",
    "\n",
    "def fix_x_generate_data(n, p, sigma_sqr, beta, nu, corr,X):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    XB = X @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1cfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to derive derivatives formula\n",
    "\n",
    "#x = symbols('x')\n",
    "#expr = 0\n",
    "#print(\"Expression : {}\".format(expr))\n",
    "\n",
    "# Use sympy.Derivative() method \n",
    "#expr_diff = Derivative(expr, x) \n",
    "\n",
    "#print(\"Derivative of expression with respect to x : {}\".format(expr_diff)) \n",
    "#print(\"Value of the derivative : {}\".format(expr_diff.doit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c843195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_sigma_prior(sigma):\n",
    "    return 1/sigma**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bb9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_likelihood(beta,sigma, nu): \n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(beta, (p, 1))\n",
    "    XB = X @ B\n",
    "    XB = XB.reshape((n, 1))\n",
    "    Z = XB/sigma_sqr\n",
    "\n",
    "    # Adopted from W6 \n",
    "    total_b2 = 0\n",
    "    total_b_sigma = 0\n",
    "    total_sigma_b = 0\n",
    "    total_s2 = 0\n",
    "    for i in range(n):\n",
    "            Xi = np.reshape(X[i,:], (p, 1))\n",
    "            residual = y[i] - X[i, :] @ beta\n",
    "            nu_sigma_sqr_plus_residual =  nu*(sigma**2)+ residual**2\n",
    "            total_b2 = total_b2 + (- (nu_sigma_sqr_plus_residual)* np.outer(X[i,:],X[i, :]) + np.outer(X[i, :], X[i, :])*2*(residual**2))/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_sigma_b = total_sigma_b + (-2*nu*sigma*X[i,:]*residual)/(nu_sigma_sqr_plus_residual**2)\n",
    "            total_s2 = total_s2 - 3 * (residual ** 2) / nu_sigma_sqr_plus_residual + ((residual ** 4) * 2 ) / (nu_sigma_sqr_plus_residual ** 2) \n",
    "\n",
    "    db2 = -1 * total_b2 * (nu+1)\n",
    "    dsb = -1 * total_sigma_b * (nu+1)\n",
    "    dbs = dsb\n",
    "    ds2 = -1 * (n / (sigma ** 2) + (nu + 1) * total_s2/(sigma**2))\n",
    "\n",
    "    dv2 = n/4 * (special.polygamma(1, (nu+1)/2) - special.polygamma(1, nu/2)) + 1/2 * np.sum((Z**2)/(nu + (Z**2)) - (Z**2 -1)/(nu + (Z**2))**2)\n",
    "\n",
    "    nu_sym = symbols('nu_sym')\n",
    "    sigma_eqt = -n/2 + (nu_sym+1)/2 * np.sum(1/(nu_sym + (Z**2)) *2*Z * (y-XB)/(sigma**2))\n",
    "    sigma_eqt= Derivative(sigma_eqt, nu_sym) \n",
    "    sigma_eqt_diff = sigma_eqt.doit()\n",
    "    dsv = sigma_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "    dvs = dsv\n",
    "\n",
    "    beta0_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,0])\n",
    "    beta0_eqt= Derivative(beta0_eqt, nu_sym) \n",
    "    beta0_eqt_diff = beta0_eqt.doit()\n",
    "    db0v = beta0_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta1_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,1])\n",
    "    beta1_eqt= Derivative(beta1_eqt, nu_sym) \n",
    "    beta1_eqt_diff = beta1_eqt.doit()\n",
    "    db1v = beta1_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta2_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,2])\n",
    "    beta2_eqt= Derivative(beta2_eqt, nu_sym) \n",
    "    beta2_eqt_diff = beta2_eqt.doit()\n",
    "    db2v = beta2_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta3_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,3])\n",
    "    beta3_eqt= Derivative(beta3_eqt, nu_sym) \n",
    "    beta3_eqt_diff = beta3_eqt.doit()\n",
    "    db3v = beta3_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    beta4_eqt = (nu_sym+1)/2 *np.sum(1/(nu_sym + (Z**2)) * 2*Z* X[:,4])\n",
    "    beta4_eqt= Derivative(beta4_eqt, nu_sym) \n",
    "    beta4_eqt_diff = beta4_eqt.doit()\n",
    "    db4v = beta4_eqt_diff.evalf(subs={nu_sym: nu})\n",
    "\n",
    "    dbv = np.array([db0v,db1v,db2v,db3v,db4v])\n",
    "    dvb = dbv\n",
    "\n",
    "    hessian_likelihood = np.zeros((p + 2, p + 2))\n",
    "    hessian_likelihood[:p, :p] = db2\n",
    "    hessian_likelihood[:p, p] = dbs\n",
    "    hessian_likelihood[p, :p] = dsb\n",
    "    hessian_likelihood[p, p] = ds2\n",
    "    hessian_likelihood[-1,-1] = dv2\n",
    "    hessian_likelihood[-2,-1] = dsv\n",
    "    hessian_likelihood[-1,-2] = dvs\n",
    "    hessian_likelihood[:p,p+1] = dbv\n",
    "    hessian_likelihood[p+1,:p] = dvb\n",
    "    \n",
    "    return hessian_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d930ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_nu_Jeff_prior(x):\n",
    "    term1 = (x + 3)*(1.0*x/(x + 3)**3 - 1.0/(x + 3)**2)/x + (-0.5*x/(x + 3)**2 + 0.5/(x + 3))/x - (x + 3)*(-0.5*x/(x + 3)**2 + 0.5/(x + 3))/x**2\n",
    "    term2 = 1/(2*(special.polygamma(1,x/2) - special.polygamma(1, (x+1)/2) - 2*(x+3)/(x*(x+1)**2)))\n",
    "    term3 = 1/4*special.polygamma(3,x/2)\n",
    "    term4 = 1/4*special.polygamma(3,(x+1)/2)\n",
    "    term5 = -8/(x*(x + 1)**3) + 3*(4*x + 12)/(x*(x + 1)**4) - 4/(x**2*(x + 1)**2) + 2*(2*x + 6)/(x**2*(x + 1)**3) + (4*x + 12)/(x**2*(x + 1)**3) + 2*(2*x + 6)/(x**3*(x + 1)**2)\n",
    "    return term1 + term2* (term3 - term4 - term5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc6610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error(beta,sigma,nu):\n",
    "    Hessian_L = hessian_likelihood(beta,sigma,nu)\n",
    "    hessian_S = hessian_sigma_prior(sigma)\n",
    "    hessian_nu = hessian_nu_Jeff_prior(nu)\n",
    "    Hessian_L[p][p] += hessian_S\n",
    "    Hessian_L[-1][-1] += hessian_nu\n",
    "    hessian_inverse = np.linalg.inv(Hessian_L)\n",
    "    sd = np.sqrt(abs(hessian_inverse[-1][-1]))\n",
    "    return sd\n",
    "\n",
    "def confidence_interval(nu_MAP, sd):\n",
    "    upper_interval = nu_MAP + 1.96*sd\n",
    "    lower_interval = nu_MAP - 1.96*sd\n",
    "    return [lower_interval,upper_interval]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92045e4a",
   "metadata": {},
   "source": [
    "# 'Nelder-Mead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aefcff94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Fix number of observations\n",
    "n = 50\n",
    "p = 5\n",
    "beta = np.array([2, 1, 0.3, 0.9, 1])\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "for nu_origin in range(5,21,5):\n",
    "    CI_list = []\n",
    "    MAP_list = []\n",
    "    count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(50): # number of simulations \n",
    "        y = fix_x_generate_data(n, p, sigma_sqr, beta, nu_origin, corr, X) \n",
    "        \n",
    "        # Maximize log joint with Nedler- Mead algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y,nu_origin)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_full_joint, initial_guess, 'Nelder-Mead')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            \n",
    "            # MAP\n",
    "            nu_MAP = profile_lse_joint_result.x[-1]\n",
    "            beta_MAP = profile_lse_joint_result.x[:p]\n",
    "            sigma_MAP = profile_lse_joint_result.x[-2]\n",
    "            MAP_list.append(nu_MAP)\n",
    "\n",
    "            # SD\n",
    "            sd = standard_error(beta_MAP,sigma_MAP,nu_MAP)\n",
    "            \n",
    "            # CI\n",
    "            CI = confidence_interval(nu_MAP, sd)\n",
    "            CI_list.append(CI)\n",
    "            \n",
    "    for CI in CI_list:\n",
    "        count_include_in_CI += CI[0]<= nu_origin<= CI[1]\n",
    "    MSE = calculate_y_axix(nu_origin, MAP_list)\n",
    "    final_dict[nu_origin] = [count_include_in_CI,len(MAP_list), MSE]\n",
    "    print(nu_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7501ace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [0, 50, 3.3665859498970763],\n",
       " 10: [0, 50, 4.481586831267373],\n",
       " 15: [0, 50, 5.3210513247268425],\n",
       " 20: [0, 50, 5.754414998412022]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a9522",
   "metadata": {},
   "source": [
    "# L-BFGS-B algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e4abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix number of observations\n",
    "n = 50\n",
    "p = 5\n",
    "beta = np.array([2, 1, 0.3, 0.9, 1])\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "for nu_origin in range(5,21):\n",
    "    CI_list = []\n",
    "    MAP_list = []\n",
    "    count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(50): # number of simulations \n",
    "        y = fix_x_generate_data(n, p, sigma_sqr, beta, nu_origin, corr, X) \n",
    "        \n",
    "        # Maximize log joint with L-BFGS-B algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y,nu_origin)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_full_joint, initial_guess, 'L-BFGS-B')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            # MAP\n",
    "            MAP = profile_lse_joint_result.x[-1]\n",
    "            MAP_list.append(MAP)\n",
    "            #print(MAP)\n",
    "            \n",
    "            # SD\n",
    "            B = profile_lse_joint_result.hess_inv  \n",
    "            B = B * np.identity(B.shape[1])  \n",
    "            sd = np.sqrt(B[-1][-1])\n",
    "            \n",
    "            # CI\n",
    "            CI = confidence_interval(MAP, sd)\n",
    "            CI_list.append(CI)\n",
    "            #print(CI)\n",
    "            \n",
    "    for CI in CI_list:\n",
    "        count_include_in_CI += CI[0]<= nu_origin<= CI[1]\n",
    "    MSE = calculate_y_axix(nu_origin, MAP_list)\n",
    "    final_dict[nu_origin] = [count_include_in_CI,len(MAP_list), MSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59ebc271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [24, 25, 2.1806004174129656],\n",
       " 6: [25, 30, 2.7372909838440145],\n",
       " 7: [34, 39, 3.332399778701354],\n",
       " 8: [32, 39, 3.3546362126474247],\n",
       " 9: [32, 43, 3.9359449895966674],\n",
       " 10: [18, 34, 3.977934097889255],\n",
       " 11: [30, 41, 4.146342064092061],\n",
       " 12: [28, 40, 4.011459864449048],\n",
       " 13: [23, 41, 4.5121784370829525],\n",
       " 14: [21, 34, 4.204581891371945],\n",
       " 15: [18, 29, 3.885378769479743],\n",
       " 16: [14, 35, 4.406776160197553],\n",
       " 17: [14, 30, 4.1230774893617825],\n",
       " 18: [10, 29, 4.1255202031886995],\n",
       " 19: [4, 24, 3.8384456039884753],\n",
       " 20: [10, 23, 3.662789395264211]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
