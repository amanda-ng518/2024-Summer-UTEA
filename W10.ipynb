{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355a88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package\n",
    "import numpy as np; from scipy import stats; import matplotlib.pyplot as plt; import pymc as pm;import arviz as az; \n",
    "import math; import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import root\n",
    "from scipy import special\n",
    "import pytensor.tensor as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18a6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Corr_identity(p):\n",
    "\n",
    "    Sigma = np.zeros((p-1, p-1))\n",
    "    np.fill_diagonal(Sigma, 1)\n",
    "    return Sigma\n",
    "\n",
    "def generate_data(n, p, sigma_sqr, beta, nu, corr):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    x_i = np.random.normal(0, 1, (n, p - 1))\n",
    "    x_i_correlated = x_i @ corr\n",
    "    ones = np.ones((n, 1))\n",
    "    x_i_full =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "    XB = x_i_full @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y, x_i_full,x_i\n",
    "\n",
    "def calculate_y_axix(nu_origin, nu_est):\n",
    "    n = len(nu_est)\n",
    "    if n == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        nu_origin_vec = nu_origin * np.ones((n, 1))\n",
    "        mse = np.sum((nu_est - nu_origin_vec)**2) / n\n",
    "        result = np.sqrt(mse)/nu_origin\n",
    "        return result\n",
    "    \n",
    "# full likelihood\n",
    "def negative_log_likelihood(params):\n",
    "    betas, sigma, nu = params[:-2], params[-2], params[-1]\n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(betas, (p, 1))\n",
    "    XB = X @ B\n",
    "    n = X.shape[0]\n",
    "    XB = XB.reshape((n, 1))\n",
    "    \n",
    "    # loglikelihood\n",
    "    equation = n * np.log(special.gamma((nu + 1)/2)) + n* nu *0.5 * np.log(nu) - n * np.log(special.gamma(nu/2)) - 0.5*n*np.log(np.pi) - n * np.log(sigma) - 0.5 *(nu + 1)*np.sum(np.log(nu + ((y - XB)/sigma)**2))\n",
    "    return -equation\n",
    "\n",
    "# Jeffrey's prior\n",
    "def logJeff(x):\n",
    "    return np.log((x/(x+3))**(1/2)*(special.polygamma(1,x/2) - special.polygamma(1, (x+1)/2) - 2*(x+3)/(x*(x+1)**2))**(1/2))\n",
    "\n",
    "# full joint\n",
    "def negative_joint(params):\n",
    "    nu = params[-1]\n",
    "    return -logJeff(nu) + negative_log_likelihood(params)\n",
    "\n",
    "def initial_guess_from_lin_reg(x_without_1, y,nu_origin):\n",
    "    initial_guess = []\n",
    "    \n",
    "    model = LinearRegression().fit(x_without_1, y)\n",
    "    # intercept \n",
    "    initial_guess.append(float(model.intercept_))\n",
    "    # coeff\n",
    "    for coeff in model.coef_[0]:\n",
    "        initial_guess.append(coeff)\n",
    "    # sigma_sq    \n",
    "    y_pred = model.predict(x_without_1)\n",
    "    residual_sq = (((y - y_pred)**2).sum())/(n-2)\n",
    "    initial_guess.append(residual_sq)\n",
    "    \n",
    "    # nu\n",
    "    initial_guess.append(nu_origin) # use true nu for initial guess\n",
    "    return initial_guess\n",
    "\n",
    "def optimizer_all_three_params_least_sq(eqt, initial_guess,method_name):\n",
    "    p = X.shape[1]\n",
    "    bounds = [(None, None)] * p +[(0, np.inf)]*2\n",
    "    result = minimize(eqt, initial_guess, method= method_name,bounds = bounds, options={'maxiter':1000})\n",
    "    return result\n",
    "\n",
    "def fix_x_generate_data(n, p, sigma_sqr, beta, nu, corr,X):\n",
    "\n",
    "    beta = beta.reshape((p, 1))\n",
    "    XB = X @ beta\n",
    "    E = stats.t.rvs(df = nu, loc=0, scale= np.sqrt(sigma_sqr), size=(n, 1))\n",
    "    Y = XB + E\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf44e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error(nu):\n",
    "    \n",
    "    p = X.shape[1]\n",
    "    B = np.reshape(beta, (p, 1))\n",
    "    XB = X @ B\n",
    "    n = X.shape[0]\n",
    "    XB = XB.reshape((n, 1))\n",
    "    Z = XB/sigma_sqr\n",
    "    \n",
    "    # special.polygamma(1,x) is trigamma at x \n",
    "    second_derivative_of_nu = n/4 * (special.polygamma(1, (nu+1)/2) - special.polygamma(1, nu/2)) + 1/2 * np.sum((Z**2)/(nu + (Z**2)) - (Z**2 -1)/(nu + (Z**2))**2)\n",
    "    return 1/ np.sqrt(second_derivative_of_nu) \n",
    "\n",
    "def confidence_interval(MAP, sd):\n",
    "    upper_interval = MAP + 1.96*sd\n",
    "    lower_interval = MAP - 1.96*sd\n",
    "    return [lower_interval,upper_interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e851a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix number of observations\n",
    "n = 50\n",
    "p = 5\n",
    "beta = np.array([2, 1, 0.3, 0.9, 1])\n",
    "sigma_sqr = 1.5\n",
    "corr = generate_Corr_identity(p)\n",
    "x_without_1 = np.random.normal(0, 1, (n, p - 1))\n",
    "x_i_correlated = x_without_1 @ corr\n",
    "ones = np.ones((n, 1))\n",
    "X =  np.concatenate((ones, x_i_correlated), axis=1)\n",
    "\n",
    "final_dict = {}\n",
    "for nu_origin in range(5,21):\n",
    "    CI_list = []\n",
    "    MAP_list = []\n",
    "    count_include_in_CI = 0\n",
    "    \n",
    "    for j in range(100): # number of simulations \n",
    "        y = fix_x_generate_data(n, p, sigma_sqr, beta, nu_origin, corr, X) \n",
    "        \n",
    "        # Maximize log joint with NM algorithm and LS intial guess to get MAP\n",
    "        initial_guess = initial_guess_from_lin_reg(x_without_1, y,nu_origin)\n",
    "        profile_lse_joint_result = optimizer_all_three_params_least_sq(negative_joint, initial_guess, 'Nelder-Mead')\n",
    "        if profile_lse_joint_result.success == True:\n",
    "            MAP = profile_lse_joint_result.x[-1]\n",
    "            MAP_list.append(MAP)\n",
    "            sd = standard_error(MAP)\n",
    "            CI_list.append(confidence_interval(MAP, sd))\n",
    "            \n",
    "    for CI in CI_list:\n",
    "        count_include_in_CI += CI[0]<= nu_origin<= CI[1]\n",
    "    MSE = calculate_y_axix(nu_origin, MAP_list)\n",
    "    final_dict[nu_origin] = [count_include_in_CI, MSE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301dc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
